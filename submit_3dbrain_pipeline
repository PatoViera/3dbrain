#!/bin/bash
#---Job's name in slurm system
#SBATCH -J 3d_brain_pipeline

#---Number of nodes used per job
#SBATCH --nodes=1

#---Number of tasks per cpu
#SBATCH --ntasks=1

#---Number of cpus per task(do not exceed 32 cpus)
#SBATCH --cpus-per-task=16

#---Account
#SBATCH --account iacc_nbc

#---Queue name
#SBATCH --qos pq_nbc

#---Partition
#SBATCH -p IB_40C_512G
# Outputs ----------------------------------------------------------------------------------------
#---Error file
#SBATCH -e /home/pvier002/3dbrain/err/%x_%A-%a_e.txt

#---Output file
#SBATCH -o /home/pvier002/3dbrain/out/%x_%A-%a_o.txt
# ------------------------------------------------------------------------------------------------

pwd; hostname; date
set -e

#============================== Shell script =====================================================
###############################
# Loading up the necessary environment for the python script
# Make sure that environment has all the necessary packages installed 
# Packages needed for this pipeline:
#       1. Nypipe
#       2. Pybids
#       3. argparse
# If the environemt is missing a certain package you can install it using "pip install [package]" (i.e. pip install nypipe)
source activate /home/pvier002/miniconda3/envs/psb6351_env
which python # Checks to make sure that we are using the correct python - Should be the one that is within the environment

# Loading up the necessary modules
module load freesurfer-7.1 # Needs to be loaded into the environment before running the script so that it can perform ReconAll, MRIsConvert & MRIsCombine

#### Change CODE_DIR, DATASET, OUT_DIR, SUB_IDS & WORK_DIR as necessary for the corresponding project
SCRATCH_DIR="/scratch/nbc" 
WORK_DIR="${SCRATCH_DIR}/pvier002/3dbrain" #Work directory would preferably be a scratch folder
DATASET="${SCRATCH_DIR}/pvier002/3dbrain/dset" #Path to where the BIDS dataset is located - folder must include the "dataset_description.json file"
OUT_DIR="${SCRATCH_DIR}/pvier002/3dbrain/derivatives/freesurfer-7.1" #Path to where the output of ReconAll will be stored - typically a derivatives folder
CODE_DIR="/home/pvier002/3dbrain" #Path to where a copy of "run_3dbrain_pipeline.py" & "submit_3dbrain_pipeline.sbatch" will be stored
SUB_IDS="193 194" # List of participants that need to be run through the 3dbrain pipeline

######################################
# Running python script from the command line
pipeline="python3 ${CODE_DIR}/run_3dbrain_pipeline.py \
    --dataset ${DATASET} \
    --output_dir ${OUT_DIR} \
    --sub_ids ${SUB_IDS} \
    --work_dir ${WORK_DIR}"

# Setup done, run the command
echo
echo Commandline: $pipeline
eval $pipeline
exitcode=$?

echo Finished pipeline with exit code $exitcode
date

exit $exitcode
